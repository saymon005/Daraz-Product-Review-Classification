{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Submission Guidelines:\n",
        "\n",
        "*   Make a copy of the file in your drive and rename the file with your id_section. e.g. **190204001_A1**\n",
        "* You will have **20 minutes** to finish the task\n",
        "* If you finish within the time **raise your hand**\n",
        "* Everyone must make the final submission of the .ipynb file in the following google form: https://forms.gle/qaDrBb61YwqQumgi6\n",
        "* **Any form of copying, plagiarism, or unauthorized collaboration is strictly prohibited and your exam will be cancelled if you are found guilty**"
      ],
      "metadata": {
        "id": "hcytwmesSpDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Online 1\n",
        "We need to complete the templete code to solve a 3 class classification problem. You nedd to complete the following tasks:\n",
        "\n",
        "1.   Step #1: **data** tensor contains the input features and the **label** tensor contains the outputs. You need to apply slicing to extract the first and last features and assign the **first 40 data** to x_data and outputs to y_data.<br>\n",
        "Additionally define the hyperparameters with **number of epochs having 100 + (last 2 digits of your id) and learning rate is 0.01**\n",
        "2.   Step #2: Design the models with following layers:<br>**Input Layer -> Linear Layer -> ReLU -> Linear Layer -> Sigmoid -> Output Layer**\n",
        "3. Step #3: Define the loss function as **Cross Entropy Loss** and Optimizer as **Stochastic Gradient Descent (SGD)**\n",
        "4. Step #4: Complete the **forwad pass and loss calculation step** in training loop\n",
        "5. Step #5: Make prediction on the last 10 samples from the data tensor and print the predicted class<br>"
      ],
      "metadata": {
        "id": "BwbPQwjWKulM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "from torch import tensor"
      ],
      "metadata": {
        "id": "gUKQEd0sRCmV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step #1 : Define input, output and hyperparameters"
      ],
      "metadata": {
        "id": "BChap70eSxoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "data = torch.rand(50, 4, dtype = torch.float32)\n",
        "data = data * 100\n",
        "data = torch.round(data)\n",
        "\n",
        "label = torch.tensor([2 if x > 70 else 1 if x < 70 and x > 40 else 0 for x in data[:, 0] ], dtype = torch.float32)\n",
        "print(label)"
      ],
      "metadata": {
        "id": "1RTT_RDDxP7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce85811f-3192-4c19-ae6b-bca16d624b04"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 0., 2., 2., 2., 0., 0., 1., 2., 1., 1., 2., 2., 0., 1., 1., 1., 0.,\n",
            "        2., 0., 0., 2., 0., 2., 2., 0., 1., 0., 1., 1., 1., 0., 2., 0., 0., 1.,\n",
            "        1., 2., 1., 2., 2., 2., 1., 2., 0., 1., 2., 0., 2., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWyCJFyUW2TQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a6f506-4e62-4259-ce68-0f77631a56e3"
      },
      "source": [
        "#Complete the following codes\n",
        "x_data = data[:40, :2]\n",
        "y_data = label[:40]\n",
        "\n",
        "print(x_data)\n",
        "print(y_data)\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = x_data.shape[1]\n",
        "output_size = 1\n",
        "num_epochs = 105\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[88., 92.],\n",
            "        [39., 60.],\n",
            "        [94., 13.],\n",
            "        [87., 57.],\n",
            "        [89., 57.],\n",
            "        [27., 44.],\n",
            "        [11., 27.],\n",
            "        [55.,  1.],\n",
            "        [89., 58.],\n",
            "        [58., 90.],\n",
            "        [63., 36.],\n",
            "        [79., 28.],\n",
            "        [75., 20.],\n",
            "        [12., 91.],\n",
            "        [66., 49.],\n",
            "        [53., 16.],\n",
            "        [65., 40.],\n",
            "        [20., 20.],\n",
            "        [98.,  9.],\n",
            "        [16., 70.],\n",
            "        [24., 16.],\n",
            "        [80., 38.],\n",
            "        [25., 65.],\n",
            "        [80., 84.],\n",
            "        [96., 33.],\n",
            "        [21., 62.],\n",
            "        [51., 16.],\n",
            "        [ 6., 18.],\n",
            "        [65.,  3.],\n",
            "        [58.,  6.],\n",
            "        [50., 31.],\n",
            "        [16., 21.],\n",
            "        [92., 40.],\n",
            "        [ 8., 85.],\n",
            "        [ 8.,  0.],\n",
            "        [69.,  9.],\n",
            "        [41., 60.],\n",
            "        [96., 10.],\n",
            "        [45., 13.],\n",
            "        [77., 68.]])\n",
            "tensor([2., 0., 2., 2., 2., 0., 0., 1., 2., 1., 1., 2., 2., 0., 1., 1., 1., 0.,\n",
            "        2., 0., 0., 2., 0., 2., 2., 0., 1., 0., 1., 1., 1., 0., 2., 0., 0., 1.,\n",
            "        1., 2., 1., 2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyV1hfzhZ4EB"
      },
      "source": [
        "### Step #2 : Design your model using class with Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6VTdaeqZ_fo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfac0c1c-557e-41c8-806e-dd9e529a0942"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #Complete the following code\n",
        "        self.linear1 = nn.Linear(input_size, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(10, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Complete the following code\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        y_pred = self.sigmoid(x)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "# our model\n",
        "model = Model()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (linear1): Linear(in_features=2, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear2): Linear(in_features=10, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B67aGn6kaDAh"
      },
      "source": [
        "###Step #3 : Construct loss and optimizer (select from PyTorch API)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj6oN5_daEUI"
      },
      "source": [
        "#Complete the following code\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I4ZfKK1uEOl"
      },
      "source": [
        "###Step #4 : Training: forward, loss, backward, step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVZw04-2uGE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed7c383b-c9eb-489d-aa37-6af8b0018c87"
      },
      "source": [
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    #Complete the following code\n",
        "    y_pred = model(x_data.to(device))\n",
        "    y_pred = y_pred.squeeze()\n",
        "    loss = criterion(y_pred, y_data.to(device))\n",
        "\n",
        "    print(f'Epoch: {epoch} | Loss: {loss.item()} ')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 148.37445068359375 \n",
            "Epoch: 1 | Loss: 151.446044921875 \n",
            "Epoch: 2 | Loss: 151.42813110351562 \n",
            "Epoch: 3 | Loss: 151.41265869140625 \n",
            "Epoch: 4 | Loss: 151.39926147460938 \n",
            "Epoch: 5 | Loss: 151.38755798339844 \n",
            "Epoch: 6 | Loss: 151.37725830078125 \n",
            "Epoch: 7 | Loss: 151.36817932128906 \n",
            "Epoch: 8 | Loss: 151.360107421875 \n",
            "Epoch: 9 | Loss: 151.3529052734375 \n",
            "Epoch: 10 | Loss: 151.34646606445312 \n",
            "Epoch: 11 | Loss: 151.34063720703125 \n",
            "Epoch: 12 | Loss: 151.33535766601562 \n",
            "Epoch: 13 | Loss: 151.33058166503906 \n",
            "Epoch: 14 | Loss: 151.3262481689453 \n",
            "Epoch: 15 | Loss: 151.32225036621094 \n",
            "Epoch: 16 | Loss: 151.318603515625 \n",
            "Epoch: 17 | Loss: 151.31524658203125 \n",
            "Epoch: 18 | Loss: 151.3121337890625 \n",
            "Epoch: 19 | Loss: 151.3092803955078 \n",
            "Epoch: 20 | Loss: 151.3065948486328 \n",
            "Epoch: 21 | Loss: 151.30413818359375 \n",
            "Epoch: 22 | Loss: 151.3018035888672 \n",
            "Epoch: 23 | Loss: 151.29966735839844 \n",
            "Epoch: 24 | Loss: 151.29766845703125 \n",
            "Epoch: 25 | Loss: 151.2957763671875 \n",
            "Epoch: 26 | Loss: 151.29400634765625 \n",
            "Epoch: 27 | Loss: 151.2923583984375 \n",
            "Epoch: 28 | Loss: 151.290771484375 \n",
            "Epoch: 29 | Loss: 151.28929138183594 \n",
            "Epoch: 30 | Loss: 151.28790283203125 \n",
            "Epoch: 31 | Loss: 151.28659057617188 \n",
            "Epoch: 32 | Loss: 151.28533935546875 \n",
            "Epoch: 33 | Loss: 151.28414916992188 \n",
            "Epoch: 34 | Loss: 151.2830352783203 \n",
            "Epoch: 35 | Loss: 151.28195190429688 \n",
            "Epoch: 36 | Loss: 151.2809295654297 \n",
            "Epoch: 37 | Loss: 151.27996826171875 \n",
            "Epoch: 38 | Loss: 151.279052734375 \n",
            "Epoch: 39 | Loss: 151.2781982421875 \n",
            "Epoch: 40 | Loss: 151.27734375 \n",
            "Epoch: 41 | Loss: 151.27651977539062 \n",
            "Epoch: 42 | Loss: 151.27572631835938 \n",
            "Epoch: 43 | Loss: 151.27500915527344 \n",
            "Epoch: 44 | Loss: 151.2742919921875 \n",
            "Epoch: 45 | Loss: 151.27365112304688 \n",
            "Epoch: 46 | Loss: 151.2729949951172 \n",
            "Epoch: 47 | Loss: 151.27235412597656 \n",
            "Epoch: 48 | Loss: 151.27175903320312 \n",
            "Epoch: 49 | Loss: 151.27117919921875 \n",
            "Epoch: 50 | Loss: 151.27061462402344 \n",
            "Epoch: 51 | Loss: 151.27008056640625 \n",
            "Epoch: 52 | Loss: 151.26956176757812 \n",
            "Epoch: 53 | Loss: 151.26905822753906 \n",
            "Epoch: 54 | Loss: 151.26858520507812 \n",
            "Epoch: 55 | Loss: 151.26812744140625 \n",
            "Epoch: 56 | Loss: 151.26768493652344 \n",
            "Epoch: 57 | Loss: 151.26724243164062 \n",
            "Epoch: 58 | Loss: 151.26681518554688 \n",
            "Epoch: 59 | Loss: 151.26641845703125 \n",
            "Epoch: 60 | Loss: 151.26602172851562 \n",
            "Epoch: 61 | Loss: 151.26565551757812 \n",
            "Epoch: 62 | Loss: 151.2652587890625 \n",
            "Epoch: 63 | Loss: 151.2649383544922 \n",
            "Epoch: 64 | Loss: 151.2645721435547 \n",
            "Epoch: 65 | Loss: 151.2642364501953 \n",
            "Epoch: 66 | Loss: 151.263916015625 \n",
            "Epoch: 67 | Loss: 151.2635955810547 \n",
            "Epoch: 68 | Loss: 151.26327514648438 \n",
            "Epoch: 69 | Loss: 151.26300048828125 \n",
            "Epoch: 70 | Loss: 151.26271057128906 \n",
            "Epoch: 71 | Loss: 151.26242065429688 \n",
            "Epoch: 72 | Loss: 151.2621307373047 \n",
            "Epoch: 73 | Loss: 151.2618865966797 \n",
            "Epoch: 74 | Loss: 151.26162719726562 \n",
            "Epoch: 75 | Loss: 151.26133728027344 \n",
            "Epoch: 76 | Loss: 151.2611083984375 \n",
            "Epoch: 77 | Loss: 151.26087951660156 \n",
            "Epoch: 78 | Loss: 151.26065063476562 \n",
            "Epoch: 79 | Loss: 151.26040649414062 \n",
            "Epoch: 80 | Loss: 151.2602081298828 \n",
            "Epoch: 81 | Loss: 151.2599639892578 \n",
            "Epoch: 82 | Loss: 151.259765625 \n",
            "Epoch: 83 | Loss: 151.2595672607422 \n",
            "Epoch: 84 | Loss: 151.2593536376953 \n",
            "Epoch: 85 | Loss: 151.2591552734375 \n",
            "Epoch: 86 | Loss: 151.2589569091797 \n",
            "Epoch: 87 | Loss: 151.25880432128906 \n",
            "Epoch: 88 | Loss: 151.2585906982422 \n",
            "Epoch: 89 | Loss: 151.25840759277344 \n",
            "Epoch: 90 | Loss: 151.25823974609375 \n",
            "Epoch: 91 | Loss: 151.25807189941406 \n",
            "Epoch: 92 | Loss: 151.2578887939453 \n",
            "Epoch: 93 | Loss: 151.25775146484375 \n",
            "Epoch: 94 | Loss: 151.25758361816406 \n",
            "Epoch: 95 | Loss: 151.25743103027344 \n",
            "Epoch: 96 | Loss: 151.25726318359375 \n",
            "Epoch: 97 | Loss: 151.2571258544922 \n",
            "Epoch: 98 | Loss: 151.2569580078125 \n",
            "Epoch: 99 | Loss: 151.2568359375 \n",
            "Epoch: 100 | Loss: 151.25668334960938 \n",
            "Epoch: 101 | Loss: 151.25653076171875 \n",
            "Epoch: 102 | Loss: 151.25640869140625 \n",
            "Epoch: 103 | Loss: 151.2563018798828 \n",
            "Epoch: 104 | Loss: 151.25613403320312 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step #5 : Prediction"
      ],
      "metadata": {
        "id": "f1eTYoS5RJrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on unseen data and print the predicted class\n",
        "test_data = data[-10:, :2]\n",
        "with torch.no_grad():\n",
        "    predictions = model(test_data.to(device))\n",
        "    predicted_classes = (predictions > 0.5).float()\n",
        "\n",
        "print(\"\\nPredicted Classes for the last 10 samples:\")\n",
        "for i in range(len(test_data)):\n",
        "    print(f'Test Data: {test_data[i]}, Predicted Class: {predicted_classes[i].item()}')\n"
      ],
      "metadata": {
        "id": "QcANaW-4Umse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e512b8c-631e-4d8f-ff94-3db5a33005be"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted Classes for the last 10 samples:\n",
            "Test Data: tensor([95., 61.]), Predicted Class: 0.0\n",
            "Test Data: tensor([71., 42.]), Predicted Class: 0.0\n",
            "Test Data: tensor([61., 22.]), Predicted Class: 0.0\n",
            "Test Data: tensor([78., 37.]), Predicted Class: 0.0\n",
            "Test Data: tensor([13., 68.]), Predicted Class: 0.0\n",
            "Test Data: tensor([62., 76.]), Predicted Class: 0.0\n",
            "Test Data: tensor([76., 76.]), Predicted Class: 0.0\n",
            "Test Data: tensor([37., 55.]), Predicted Class: 0.0\n",
            "Test Data: tensor([82., 93.]), Predicted Class: 0.0\n",
            "Test Data: tensor([51., 47.]), Predicted Class: 0.0\n"
          ]
        }
      ]
    }
  ]
}
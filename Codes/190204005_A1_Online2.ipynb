{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Submission Guidelines:\n",
        "\n",
        "*   Make a copy of the file in your drive and rename the file with your id_section. e.g. **190204001_A1**\n",
        "* You will have **20 minutes** to finish the task\n",
        "* Everyone must make the final submission of the .ipynb file in the following google form: https://forms.gle/iDPs5ZrWJiPq5Yfh6\n",
        "* **Any form of copying, plagiarism, or unauthorized collaboration is strictly prohibited and your exam will be cancelled if you are found guilty**"
      ],
      "metadata": {
        "id": "NQMRgDxZngSW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "omcY7PFbnNVC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "LOADING DATASET\n",
        "'''\n",
        "batch_size = 100\n",
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "'''\n",
        "MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)   # It's better to shuffle the whole training dataset!\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "dJGF0RTCpUQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac47638a-8f8b-423d-d783-ea37c7e1dcb2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 111105885.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 116588733.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 30403531.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5824068.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task\n",
        "You will train a Neural Network for 2 epochs on the MNIST dataset. Your Neural Network will habe 3 hidden layers. First Hidden layer will have 200 neurons, Second Hidden layer will have 100 neurons, Third Hidden layer will have 50 neurons. Use LeakyReLU as activation function for the hidden layers."
      ],
      "metadata": {
        "id": "Y5OxclEIvka-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Edit Following Cell**"
      ],
      "metadata": {
        "id": "Hu6gFfzcvIg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Initialize following variable with appropriate values\n",
        "input_dim = 28 * 28\n",
        "num_hidden = [200, 100, 50]\n",
        "output_dim = 10\n",
        "num_epochs = 2\n",
        "\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "9kKlZ5HEsX5n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Edit Following Cell**"
      ],
      "metadata": {
        "id": "WrGsQ4vKscZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "\n",
        "        ### Enter Your Code Here\n",
        "        self.layer1 = nn.Linear(input_size, num_hidden[0])\n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "        self.layer2 = nn.Linear(num_hidden[0], num_hidden[1])\n",
        "        self.relu2 = nn.LeakyReLU()\n",
        "        self.layer3 = nn.Linear(num_hidden[1], num_hidden[2])\n",
        "        self.relu3 = nn.LeakyReLU()\n",
        "        self.output_layer = nn.Linear(num_hidden[2], num_classes)\n",
        "        ### End Your Code Here\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### Enter Your Code Here\n",
        "        out = self.layer1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.relu3(out)\n",
        "        out = self.output_layer(out)\n",
        "        return out\n",
        "        ### End Your Code Here"
      ],
      "metadata": {
        "id": "X8OWE-W2pZaA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetworkModel(input_size = input_dim,\n",
        "                           num_classes = output_dim,\n",
        "                           num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "M-AXALJHp1DW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Edit Following Cell**"
      ],
      "metadata": {
        "id": "h-v61NB6q9CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, input_dim).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        ### Enter Your Code Here\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        ### End Your Code Here\n",
        "\n"
      ],
      "metadata": {
        "id": "U38GHyVip__H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "# Iterate through test dataset\n",
        "for images, labels in test_loader:\n",
        "\n",
        "    images = images.view(-1, 28*28).to(device)\n",
        "\n",
        "    # Forward pass only to get logits/output\n",
        "    outputs = model(images)\n",
        "\n",
        "    # Get predictions from the maximum value\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # Total number of labels\n",
        "    total += labels.size(0)\n",
        "\n",
        "\n",
        "    # Total correct predictions\n",
        "    if torch.cuda.is_available():\n",
        "        correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "    else:\n",
        "        correct += (predicted == labels).sum()\n",
        "\n",
        "accuracy = 100 * correct.item() / total\n",
        "\n",
        "# Print Loss\n",
        "print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "metadata": {
        "id": "9CJ3RQ7-tVXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "678343d0-c9b2-47ff-f3f5-239b17dfe819"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0. Loss: 0.31114134192466736. Accuracy: 93.88\n"
          ]
        }
      ]
    }
  ]
}